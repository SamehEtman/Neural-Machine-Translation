{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "NMT-Arabic->English.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IF3LjvXqdJi"
      },
      "source": [
        "import tensorflow as tf\n",
        "import unicodedata\n",
        "import string\n",
        "import numpy as np\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUoGvxNddFHh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f1d6d45-271d-4a67-d7dc-cfea3cbdff4b"
      },
      "source": [
        "drive.mount(\"/content/gdrive\")"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44g54wKWqdJp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be4de972-db22-4b11-d9ea-41942750f2d8"
      },
      "source": [
        "keras = tf.keras\n",
        "print(tf.__version__)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHgfCZXVqdJu"
      },
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSK6zPRUqdJz"
      },
      "source": [
        "class Lang(object):\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2int = {}\n",
        "        self.word2count = {}\n",
        "        self.int2word = {0 : \"SOS\", 1 : \"EOS\"}\n",
        "        self.n_words = 2\n",
        "        \n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2int:\n",
        "            self.word2int[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.int2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "            \n",
        "        else:\n",
        "            self.word2count[word] += 1\n",
        "    \n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(\" \"):\n",
        "            self.addWord(word)"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8UujikttqdJ7"
      },
      "source": [
        "def unicodeToAscii(s):\n",
        "    return \"\".join(c for c in unicodedata.normalize(\"NFD\", s) \\\n",
        "                   if unicodedata.category(c) != \"Mn\")"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sb0sLusAqdKA"
      },
      "source": [
        "def normalizeString(text):\n",
        "  text = text.strip()\n",
        "  text = re.sub(\"[إأٱآا]\", \"ا\", text)\n",
        "  text = re.sub(\"ى\", \"ي\", text)\n",
        "  text = re.sub(\"ؤ\", \"ء\", text)\n",
        "  text = re.sub(\"ئ\", \"ء\", text)\n",
        "  text = re.sub(\"ة\", \"ه\", text)\n",
        "  noise = re.compile(\"\"\" ّ    | # Tashdid\n",
        "                            َ    | # Fatha\n",
        "                            ً    | # Tanwin Fath\n",
        "                            ُ    | # Damma\n",
        "                            ٌ    | # Tanwin Damm\n",
        "                            ِ    | # Kasra\n",
        "                            ٍ    | # Tanwin Kasr\n",
        "                            ْ    | # Sukun\n",
        "                            ـ     # Tatwil/Kashida\n",
        "                        \"\"\", re.VERBOSE)\n",
        "  text = re.sub(noise, '', text)\n",
        "  text = re.sub(r'(.)\\1+', r\"\\1\\1\", text) \n",
        "  \n",
        "  return text.lower()\n"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbvFe0iqqdKF"
      },
      "source": [
        "def load_dataset():\n",
        "    with open(\"/content/gdrive/MyDrive/ar.txt\",'r') as f:\n",
        "        lines = f.readlines()\n",
        "    \n",
        "    pairs = [[normalizeString(pair) for pair in \n",
        "              line.strip().split('\\t')][0:2] for line in lines]\n",
        "    return pairs"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26fM5LRUqdKJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80cd15d9-3486-40a9-97dc-545349f0f6be"
      },
      "source": [
        "pairs = load_dataset()\n",
        "pairs[2]"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a box of matches', 'علبه كبريت']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Z1ZlNzQA1ym"
      },
      "source": [
        "pairs_2 = []\n",
        "[pairs_2.append(x) for x in pairs if x not in pairs_2]\n",
        "pairs = pairs_2\n"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQbB37mcsHb_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c30a0fc-50c3-45ec-f548-dfa07546bd8b"
      },
      "source": [
        "pairs[1]\n"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a block of flats', 'مجموعه شقق سكنيه متلاصقه']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnmGqtDOqdKN"
      },
      "source": [
        "MAX_LENGTH = 10\n",
        "def filterPair(p):\n",
        "    return len(p[0].split()) < MAX_LENGTH and \\\n",
        "len(p[1].split()) < MAX_LENGTH\n",
        "\n",
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)]\n",
        "\n",
        "pairs = filterPairs(pairs)\n",
        "\n",
        "def sentencetoIndexes(sentence, lang):\n",
        "    indexes = [lang.word2int[word] for word in sentence.split()]\n",
        "    indexes.append(EOS_token)\n",
        "    return indexes\n",
        "\n"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlAGPZShqdKT"
      },
      "source": [
        "def build_lang(lang1, lang2, max_length=10):\n",
        "    input_lang = Lang(lang1)\n",
        "    output_lang = Lang(lang2)\n",
        "    input_seq = []\n",
        "    output_seq = []\n",
        "    \n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[1])\n",
        "        output_lang.addSentence(pair[0])\n",
        "    for pair in pairs:\n",
        "        input_seq.append(sentencetoIndexes(pair[1], input_lang))\n",
        "        output_seq.append(sentencetoIndexes(pair[0], output_lang))\n",
        "    return keras.preprocessing.sequence.pad_sequences(input_seq, maxlen=max_length, padding='post',\n",
        "                                                      truncating='post'), \\\n",
        "keras.preprocessing.sequence.pad_sequences(output_seq, padding='post', truncating='post'),\\\n",
        "input_lang, output_lang"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9MAxjU-qdKY"
      },
      "source": [
        "input_tensor, output_tensor, input_lang, output_lang = build_lang('ar', 'en')"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZ8Pcm1Ls8Cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a24666d-7fc8-4107-b55d-ae13ee5a81c4"
      },
      "source": [
        "print(\"input_tensor at index 10: {}\".format(input_tensor[10]))\n",
        "print(\"output_tensor at index 10: {}\".format(output_tensor[10]))\n",
        "print(\"corresponding integer value for 'انا' {}\".format(input_lang.word2int['انا']))\n",
        "print(\"corresponding integer value for 'want' {}\".format(output_lang.word2int['want']))"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input_tensor at index 10: [26 27  1  0  0  0  0  0  0  0]\n",
            "output_tensor at index 10: [ 2 23  1  0  0  0  0  0  0  0]\n",
            "corresponding integer value for 'انا' 1918\n",
            "corresponding integer value for 'want' 3156\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qii6d6iKqdKc"
      },
      "source": [
        "BATCH_SIZE = 16\n",
        "BUFFER_SIZE = len(input_tensor)\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor, output_tensor))\\\n",
        "                                                        .shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE)"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41nSXuflqdKh"
      },
      "source": [
        "class Encoder(keras.models.Model):\n",
        "    def __init__(self, vocab_size, num_hidden=256, num_embedding=256, batch_size=16):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.batch_size = batch_size\n",
        "        self.num_hidden = num_hidden\n",
        "        self.num_embedding = num_embedding\n",
        "        self.embedding = keras.layers.Embedding(vocab_size, num_embedding)\n",
        "        self.gru = keras.layers.GRU(num_hidden, return_sequences=True,\n",
        "                                    recurrent_initializer='glorot_uniform',\n",
        "                                   return_state=True)\n",
        "        \n",
        "    def call(self, x, hidden):\n",
        "        embedded = self.embedding(x)\n",
        "        rnn_out, hidden = self.gru(embedded, initial_state=hidden)\n",
        "        return rnn_out, hidden\n",
        "    def init_hidden(self):\n",
        "        return tf.zeros(shape=(self.batch_size, self.num_hidden))"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qm8zLgoqdKk"
      },
      "source": [
        "inputs, outputs = next(iter(dataset))\n",
        "hidden = tf.zeros((16, 256))"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5AHvxMiqdKo"
      },
      "source": [
        "encoder = Encoder(input_lang.n_words)"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCF-S8fBqdKs"
      },
      "source": [
        "e_outputs, e_hidden = encoder(inputs, hidden)"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqGefguVqdKv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf624738-7d83-46b4-a98b-9eb23270fcec"
      },
      "source": [
        "e_hidden"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(16, 256), dtype=float32, numpy=\n",
              "array([[ 0.01334922, -0.00613109, -0.01270204, ..., -0.01048437,\n",
              "        -0.00603429, -0.00377161],\n",
              "       [ 0.01867652, -0.00535181, -0.02266036, ..., -0.01269673,\n",
              "        -0.00490011, -0.00879866],\n",
              "       [ 0.0254486 , -0.01196414, -0.02703875, ..., -0.01560366,\n",
              "        -0.01149636, -0.01401618],\n",
              "       ...,\n",
              "       [ 0.02449796, -0.01126191, -0.02690011, ..., -0.01577139,\n",
              "        -0.01048661, -0.01394613],\n",
              "       [ 0.0248558 , -0.01136032, -0.02659996, ..., -0.01587146,\n",
              "        -0.01082783, -0.01405934],\n",
              "       [ 0.02498071, -0.01171136, -0.02573386, ..., -0.01618567,\n",
              "        -0.01089381, -0.01451182]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bJHJsq1qdK6"
      },
      "source": [
        "class BahdanauAttention(keras.models.Model):\n",
        "    def __init__(self, units):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "    \n",
        "        self.W1 = keras.layers.Dense(units)\n",
        "        self.W2 = keras.layers.Dense(units)\n",
        "        self.V = keras.layers.Dense(1)\n",
        "        \n",
        "    def call(self, encoder_out, hidden):\n",
        "        #shape of encoder_out : batch_size, seq_length, hidden_dim \n",
        "        #shape of encoder_hidden : batch_size, hidden_dim \n",
        "        \n",
        "        hidden = tf.expand_dims(hidden, axis=1) #out:\n",
        "        \n",
        "        score = self.V(tf.nn.tanh(self.W1(encoder_out) + \\\n",
        "                                  self.W2(hidden))) \n",
        "        \n",
        "        attn_weights = tf.nn.softmax(score, axis=1)\n",
        "        \n",
        "        context =  attn_weights * encoder_out \n",
        "        context = tf.reduce_sum(context, axis=1)\n",
        "        return context, attn_weights\n",
        "        "
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gRC60cCqdK-"
      },
      "source": [
        "attn = BahdanauAttention(256)"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHU6rIRzqdLC"
      },
      "source": [
        "context, attn_weights = attn(e_outputs, e_hidden)"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2XacZYkqdLK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77144704-d200-4e2a-eed5-02570aed69a5"
      },
      "source": [
        "attn_weights.shape"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([16, 10, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsLImrCwqdLT"
      },
      "source": [
        "class Decoder(keras.models.Model):\n",
        "    def __init__(self, vocab_size, dec_dim=256, embedding_dim=256):\n",
        "        super(Decoder, self).__init__()\n",
        "        \n",
        "        self.attn = BahdanauAttention(dec_dim)\n",
        "        self.embedding = keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = keras.layers.GRU(dec_dim, recurrent_initializer='glorot_uniform',\n",
        "                                   return_sequences=True, return_state=True)\n",
        "        self.fc = keras.layers.Dense(vocab_size)\n",
        "        \n",
        "    def call(self, x, enc_hidden, enc_out):\n",
        "        x = self.embedding(x)\n",
        "        context, attn_weights = self.attn(enc_out, enc_hidden)\n",
        "        x = tf.concat((tf.expand_dims(context, 1), x), -1)\n",
        "        r_out, hidden = self.gru(x, initial_state=enc_hidden)\n",
        "        out = tf.reshape(r_out,shape=(-1, r_out.shape[2]))\n",
        "        return self.fc(out), hidden, attn_weights"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItYHAqWJqdLY"
      },
      "source": [
        "decoder = Decoder(output_lang.n_words)"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnhNtfb9qdLe"
      },
      "source": [
        "input_tensor, output_tensor = next(iter(dataset))"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7Y7QsykqdLi"
      },
      "source": [
        "x = np.expand_dims(output_tensor[:,1], -1)"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DE7fnvAqdLp"
      },
      "source": [
        "@tf.function\n",
        "def loss_fn(real, pred):\n",
        "    criterion = keras.losses.SparseCategoricalCrossentropy(from_logits=True,\n",
        "                                                           reduction='none')\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    _loss = criterion(real, pred)\n",
        "    mask = tf.cast(mask, dtype=_loss.dtype)\n",
        "    _loss *= mask\n",
        "    return tf.reduce_mean(_loss)"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMc7zD6WqdLt"
      },
      "source": [
        "optimizer = tf.optimizers.Adam()"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiAmynEsqdLw"
      },
      "source": [
        "def train_step(input_tensor, target_tensor, enc_hidden):\n",
        "    loss = 0.0\n",
        "    with tf.GradientTape() as tape:\n",
        "    \n",
        "        batch_size = input_tensor.shape[0]\n",
        "        enc_output, enc_hidden = encoder(input_tensor, enc_hidden)\n",
        "\n",
        "        SOS_tensor = np.array([SOS_token])\n",
        "        dec_input = tf.squeeze(tf.expand_dims([SOS_tensor]*batch_size, 1), -1)\n",
        "        dec_hidden = enc_hidden\n",
        "\n",
        "        for tx in range(target_tensor.shape[1]-1):\n",
        "          \n",
        "            dec_out, dec_hidden, _ = decoder(dec_input, dec_hidden,\n",
        "                                            enc_output)\n",
        "            loss += loss_fn(target_tensor[:, tx], dec_out)\n",
        "            dec_input = tf.expand_dims(target_tensor[:, tx], 1)\n",
        "\n",
        "    batch_loss = loss / target_tensor.shape[1]\n",
        "    t_variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "    gradients = tape.gradient(loss, t_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, t_variables))\n",
        "    return batch_loss\n",
        "    "
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kj6diJMqdL0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcd6352d-8c65-46f0-84c3-3735290ccfc6"
      },
      "source": [
        "hidden = tf.zeros(shape=(16, 256))\n",
        "loss = train_step(input_tensor, output_tensor, hidden)\n",
        "print(loss)"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(5.954051, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lk_OG391qdL5"
      },
      "source": [
        "def checkpoint(model, name=None):\n",
        "    if name is not None:\n",
        "        model.save_weights('/content/gdrive/MyDrive/{}.h5'.format(name))\n",
        "    else:\n",
        "        raise NotImplementedError"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMKUiRwEU4C4"
      },
      "source": [
        "encoder.load_weights('/content/gdrive/MyDrive/encoder.h5')\n",
        "decoder.load_weights('/content/gdrive/MyDrive/decoder.h5')"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZEbkwx9qdL-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "140e249e-7e3c-4f60-b03d-27854b65e0a9"
      },
      "source": [
        "EPOCHS = 10\n",
        "log_every = 50\n",
        "steps_per_epoch = len(pairs) // BATCH_SIZE\n",
        "loss_list = []\n",
        "\n",
        "for e in range(1, EPOCHS):\n",
        "    \n",
        "    total_loss = 0.0\n",
        "    enc_hidden = encoder.init_hidden()\n",
        "    \n",
        "    for idx, (input_tensor, target_tensor) in enumerate(dataset.take\\\n",
        "                                                        (steps_per_epoch)):\n",
        "        batch_loss = train_step(input_tensor, target_tensor, hidden)\n",
        "        total_loss += batch_loss\n",
        "        \n",
        "        if idx % log_every == 0:\n",
        "            loss_list.append(batch_loss)\n",
        "            print(\"Epochs: {} batch_loss: {:.4f}\".format(e, batch_loss))\n",
        "            checkpoint(encoder, 'encoder')\n",
        "            checkpoint(decoder, 'decoder')\n",
        "            \n",
        "    if e % 1 == 0:\n",
        "        print(\"Epochs: {}/{} total_loss: {:.4f}\".format(\n",
        "        e, EPOCHS, total_loss / steps_per_epoch))"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epochs: 1 batch_loss: 0.0375\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-116-4e462c6bd19f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_tensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m                                                        \u001b[0;34m(\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-112-eeecefc48bcf>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(input_tensor, target_tensor, enc_hidden)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtarget_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mt_variables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbatch_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1078\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1079\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1080\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1082\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     75\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    157\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_grad.py\u001b[0m in \u001b[0;36m_MatMulGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m   1731\u001b[0m   \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1732\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt_a\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt_b\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1733\u001b[0;31m     \u001b[0mgrad_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_b\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1734\u001b[0m     \u001b[0mgrad_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt_a\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mt_b\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[0;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[1;32m   5695\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[1;32m   5696\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"MatMul\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"transpose_a\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"transpose_b\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5697\u001b[0;31m         transpose_b)\n\u001b[0m\u001b[1;32m   5698\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5699\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vgs87LN7Y01x"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuswAWMYqdME"
      },
      "source": [
        "def translate(sentence, max_length=10):\n",
        "    result = ''\n",
        "    attention_plot = np.zeros((10,10))\n",
        "    sentence = normalizeString(sentence)\n",
        "    sentence = sentencetoIndexes(sentence, input_lang)\n",
        "    sentence = keras.preprocessing.sequence.pad_sequences([sentence],\\\n",
        "                                                          padding='post',\n",
        "                                                      maxlen=max_length,\\\n",
        "                                                       truncating='post')\n",
        "    \n",
        "    encoder_hidden = hidden = [tf.zeros((1, 256))]\n",
        "    \n",
        "    enc_out, enc_hidden = encoder(sentence, encoder_hidden)\n",
        "    \n",
        "    dec_hidden = enc_hidden\n",
        "    SOS_tensor = np.array([SOS_token])\n",
        "    dec_input = tf.squeeze(tf.expand_dims([SOS_tensor], 1), -1)\n",
        "    \n",
        "    for tx in range(max_length):\n",
        "        dec_out, dec_hidden, attn_weights = decoder(dec_input,\n",
        "                                                   dec_hidden, enc_out)\n",
        "        attn_weights = tf.reshape(attn_weights, (-1, ))\n",
        "        attention_plot[tx] = attn_weights.numpy()\n",
        "        pred = tf.argmax(dec_out, axis=1).numpy()\n",
        "        result += output_lang.int2word[pred[0]] + \" \"\n",
        "        if output_lang.int2word[pred[0]] == \"EOS\":\n",
        "            break\n",
        "        dec_input = tf.expand_dims(pred, axis=1)\n",
        "    return result, attention_plot"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7mmzYUIqdMI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c79a1be-29ef-473a-de23-d40be4b70fcf"
      },
      "source": [
        "sentence = \"هل انت مشغول غداً صباحاً \"\n",
        "pred, attn_weights = translate(sentence)\n",
        "print(pred)"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "are you busy tomorrow morning? EOS \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlmTbJkmjRib"
      },
      "source": [
        "encoder.save_weights('/content/gdrive/MyDrive/encoder.h5')\n",
        "decoder.save_weights('/content/gdrive/MyDrive/decoder.h5')"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-s9cnSvUxNIC"
      },
      "source": [
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "    #sentence = normalizeString(sentence)\n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    ax.matshow(attention, cmap='viridis')\n",
        "\n",
        "    fontdict = {'fontsize': 14}\n",
        "\n",
        "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpf4T5z_3JP4"
      },
      "source": [
        "from matplotlib import ticker"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5A9xpAf6xsgL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 636
        },
        "outputId": "c7454935-04d0-4756-873c-9f46200fc823"
      },
      "source": [
        "attn_weights = attn_weights[:len(pred.split(' ')), :len(sentence.split(' '))]\n",
        "plot_attention(attn_weights, sentence.split(), pred.split())"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yROfA7newSua"
      },
      "source": [
        "import anvil.server\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vDXB800z9GC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "151ec05c-7fab-489b-f68e-5fca4fa307b2"
      },
      "source": [
        "pip install anvil-uplink"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting anvil-uplink\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/65/776713490bfd5145ddb87834355bf7936bd233b273098e37dc12f1ac253c/anvil_uplink-0.3.36-py2.py3-none-any.whl (61kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 6.6MB/s \n",
            "\u001b[?25hCollecting ws4py\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/53/20/4019a739b2eefe9282d3822ef6a225250af964b117356971bd55e274193c/ws4py-0.5.1.tar.gz (51kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 7.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from anvil-uplink) (0.16.0)\n",
            "Collecting argparse\n",
            "  Downloading https://files.pythonhosted.org/packages/f2/94/3af39d34be01a24a6e65433d19e107099374224905f1e0cc6bbe1fd22a2f/argparse-1.4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from anvil-uplink) (1.15.0)\n",
            "Building wheels for collected packages: ws4py\n",
            "  Building wheel for ws4py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ws4py: filename=ws4py-0.5.1-cp37-none-any.whl size=45230 sha256=919b5d99dd60afad41b041b59f288185c36b634ac8d0e270df0ef5103adc1a6e\n",
            "  Stored in directory: /root/.cache/pip/wheels/a2/6e/4e/8b0ae12fb9b8a05715256952cf7609a8ab86285fab99b88c68\n",
            "Successfully built ws4py\n",
            "Installing collected packages: ws4py, argparse, anvil-uplink\n",
            "Successfully installed anvil-uplink-0.3.36 argparse-1.4.0 ws4py-0.5.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "argparse",
                  "google"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdJb4OLsdM12"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}