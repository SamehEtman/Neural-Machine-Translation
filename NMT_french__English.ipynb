{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "NMT_french->English.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IF3LjvXqdJi"
      },
      "source": [
        "import tensorflow as tf\n",
        "import unicodedata\n",
        "import string\n",
        "import numpy as np\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUoGvxNddFHh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "092888c8-8985-4ce0-f763-a6139d1f9530"
      },
      "source": [
        "drive.mount(\"/content/gdrive\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44g54wKWqdJp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4acc4265-3622-40fa-bc56-34cac55e5c88"
      },
      "source": [
        "keras = tf.keras\n",
        "print(tf.__version__)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEed-KleNdUK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d12d5b8-7726-4455-e16a-13651a629ab3"
      },
      "source": [
        "!wget https://www.manythings.org/anki/fra-eng.zip\n",
        "!unzip  fra-eng.zip"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-12 12:56:55--  https://www.manythings.org/anki/fra-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 172.67.173.198, 104.21.55.222, 2606:4700:3031::6815:37de, ...\n",
            "Connecting to www.manythings.org (www.manythings.org)|172.67.173.198|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6444324 (6.1M) [application/zip]\n",
            "Saving to: ‘fra-eng.zip’\n",
            "\n",
            "fra-eng.zip         100%[===================>]   6.15M  23.6MB/s    in 0.3s    \n",
            "\n",
            "2021-07-12 12:56:56 (23.6 MB/s) - ‘fra-eng.zip’ saved [6444324/6444324]\n",
            "\n",
            "Archive:  fra-eng.zip\n",
            "  inflating: _about.txt              \n",
            "  inflating: fra.txt                 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHgfCZXVqdJu"
      },
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSK6zPRUqdJz"
      },
      "source": [
        "class Lang(object):\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2int = {}\n",
        "        self.word2count = {}\n",
        "        self.int2word = {0 : \"SOS\", 1 : \"EOS\"}\n",
        "        self.n_words = 2\n",
        "        \n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2int:\n",
        "            self.word2int[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.int2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "            \n",
        "        else:\n",
        "            self.word2count[word] += 1\n",
        "    \n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(\" \"):\n",
        "            self.addWord(word)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8UujikttqdJ7"
      },
      "source": [
        "def unicodeToAscii(s):\n",
        "    return \"\".join(c for c in unicodedata.normalize(\"NFD\", s) \\\n",
        "                   if unicodedata.category(c) != \"Mn\")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sb0sLusAqdKA"
      },
      "source": [
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    \n",
        "    s = re.sub(r\"([!.?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Z?.!]+\", \" \", s)\n",
        "    return s"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbvFe0iqqdKF"
      },
      "source": [
        "def load_dataset():\n",
        "    with open(\"fra.txt\",'r') as f:\n",
        "        lines = f.readlines()\n",
        "    \n",
        "    pairs = [[normalizeString(pair) for pair in \n",
        "              line.strip().split('\\t')] for line in lines]\n",
        "    return pairs"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26fM5LRUqdKJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c332cfb5-10d8-4573-fec0-6f8cd2621cda"
      },
      "source": [
        "pairs = load_dataset()\n",
        "pairs[0]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['go .', 'va !', 'cc by . france attribution tatoeba .org cm wittydev ']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnmGqtDOqdKN"
      },
      "source": [
        "MAX_LENGTH = 10\n",
        "def sentencetoIndexes(sentence, lang):\n",
        "    indexes = [lang.word2int[word] for word in sentence.split()]\n",
        "    indexes.append(EOS_token)\n",
        "    return indexes\n",
        "\n",
        "def filterPair(p):\n",
        "    return len(p[0].split()) < MAX_LENGTH and \\\n",
        "len(p[1].split()) < MAX_LENGTH\n",
        "\n",
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)]\n",
        "\n",
        "pairs = filterPairs(pairs)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQbB37mcsHb_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d06729b-00cd-4d12-d0ad-d2ce4e4cba99"
      },
      "source": [
        "print(pairs[0])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['go .', 'va !', 'cc by . france attribution tatoeba .org cm wittydev ']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlAGPZShqdKT"
      },
      "source": [
        "def build_lang(lang1, lang2, max_length=10):\n",
        "    input_lang = Lang(lang1)\n",
        "    output_lang = Lang(lang2)\n",
        "    input_seq = []\n",
        "    output_seq = []\n",
        "    \n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[1])\n",
        "        output_lang.addSentence(pair[0])\n",
        "    for pair in pairs:\n",
        "        input_seq.append(sentencetoIndexes(pair[1], input_lang))\n",
        "        output_seq.append(sentencetoIndexes(pair[0], output_lang))\n",
        "    return keras.preprocessing.sequence.pad_sequences(input_seq, \\\n",
        "                                                      maxlen=max_length, \\\n",
        "                                                      padding='post',\n",
        "                                                      truncating='post'), \\\n",
        "keras.preprocessing.sequence.pad_sequences(output_seq, padding='post', \\\n",
        "                                           truncating='post'), input_lang, \\\n",
        "                                           output_lang"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9MAxjU-qdKY"
      },
      "source": [
        "input_tensor, output_tensor, input_lang, output_lang = build_lang('fr', 'en')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZ8Pcm1Ls8Cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "619a1ec0-882b-4e1f-e4f9-169afc712a4f"
      },
      "source": [
        "input_lang.name"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'fr'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qii6d6iKqdKc"
      },
      "source": [
        "BATCH_SIZE = 16\n",
        "BUFFER_SIZE = len(input_tensor)\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor, output_tensor)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41nSXuflqdKh"
      },
      "source": [
        "class Encoder(keras.models.Model):\n",
        "    def __init__(self, vocab_size, num_hidden=256, num_embedding=256, batch_size=16):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.batch_size = batch_size\n",
        "        self.num_hidden = num_hidden\n",
        "        self.num_embedding = num_embedding\n",
        "        self.embedding = keras.layers.Embedding(vocab_size, num_embedding)\n",
        "        self.gru = keras.layers.GRU(num_hidden, return_sequences=True,\n",
        "                                    recurrent_initializer='glorot_uniform',\n",
        "                                   return_state=True)\n",
        "        \n",
        "    def call(self, x, hidden):\n",
        "        embedded = self.embedding(x)\n",
        "        rnn_out, hidden = self.gru(embedded, initial_state=hidden)\n",
        "        return rnn_out, hidden\n",
        "    def init_hidden(self):\n",
        "        return tf.zeros(shape=(self.batch_size, self.num_hidden))"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qm8zLgoqdKk"
      },
      "source": [
        "inputs, outputs = next(iter(dataset))\n",
        "hidden = tf.zeros((16, 256))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5AHvxMiqdKo"
      },
      "source": [
        "encoder = Encoder(input_lang.n_words)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCF-S8fBqdKs"
      },
      "source": [
        "e_outputs, e_hidden = encoder(inputs, hidden)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqGefguVqdKv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aec8bffa-9f43-4d7f-ab0a-f6c9a41611c5"
      },
      "source": [
        "e_hidden"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(16, 256), dtype=float32, numpy=\n",
              "array([[ 0.00034276,  0.02808314,  0.01045971, ..., -0.00757822,\n",
              "         0.01134047,  0.02701335],\n",
              "       [-0.00848547,  0.04085872,  0.01802279, ..., -0.00620697,\n",
              "         0.01674816,  0.02879411],\n",
              "       [ 0.00024312,  0.02611962,  0.00476594, ..., -0.01048841,\n",
              "         0.01061282,  0.02209924],\n",
              "       ...,\n",
              "       [ 0.00351374,  0.02654258,  0.01044438, ..., -0.00841664,\n",
              "         0.01311381,  0.02593761],\n",
              "       [ 0.01113277,  0.00980283,  0.00015627, ..., -0.01919041,\n",
              "         0.0280209 ,  0.02877855],\n",
              "       [ 0.00208882,  0.02278279,  0.00614321, ..., -0.0093428 ,\n",
              "         0.01605869,  0.0210402 ]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bJHJsq1qdK6"
      },
      "source": [
        "class BahdanauAttention(keras.models.Model):\n",
        "    def __init__(self, units):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "    \n",
        "        self.W1 = keras.layers.Dense(units)\n",
        "        self.W2 = keras.layers.Dense(units)\n",
        "        self.V = keras.layers.Dense(1)\n",
        "        \n",
        "    def call(self, encoder_out, hidden):\n",
        "        #shape of encoder_out : batch_size, seq_length, hidden_dim \n",
        "        #shape of encoder_hidden : batch_size, hidden_dim \n",
        "        \n",
        "        hidden = tf.expand_dims(hidden, axis=1) #out:\n",
        "        \n",
        "        score = self.V(tf.nn.tanh(self.W1(encoder_out) + \\\n",
        "                                  self.W2(hidden))) \n",
        "        \n",
        "        attn_weights = tf.nn.softmax(score, axis=1)\n",
        "        \n",
        "        context =  attn_weights * encoder_out \n",
        "        context = tf.reduce_sum(context, axis=1)\n",
        "        return context, attn_weights\n",
        "        "
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gRC60cCqdK-"
      },
      "source": [
        "attn = BahdanauAttention(256)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHU6rIRzqdLC"
      },
      "source": [
        "context, attn_weights = attn(e_outputs, e_hidden)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2XacZYkqdLK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9213764c-9a20-4576-bdd2-9e7fcbc58a69"
      },
      "source": [
        "attn_weights.shape"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([16, 10, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsLImrCwqdLT"
      },
      "source": [
        "class Decoder(keras.models.Model):\n",
        "    def __init__(self, vocab_size, dec_dim=256, embedding_dim=256):\n",
        "        super(Decoder, self).__init__()\n",
        "        \n",
        "        self.attn = BahdanauAttention(dec_dim)\n",
        "        self.embedding = keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = keras.layers.GRU(dec_dim, recurrent_initializer='glorot_uniform',\n",
        "                                   return_sequences=True, return_state=True)\n",
        "        self.fc = keras.layers.Dense(vocab_size)\n",
        "        \n",
        "    def call(self, x, enc_hidden, enc_out):\n",
        "        x = self.embedding(x)\n",
        "        context, attn_weights = self.attn(enc_out, enc_hidden)\n",
        "        x = tf.concat((tf.expand_dims(context, 1), x), -1)\n",
        "        r_out, hidden = self.gru(x, initial_state=enc_hidden)\n",
        "        out = tf.reshape(r_out,shape=(-1, r_out.shape[2]))\n",
        "        return self.fc(out), hidden, attn_weights"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItYHAqWJqdLY"
      },
      "source": [
        "decoder = Decoder(output_lang.n_words)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnhNtfb9qdLe"
      },
      "source": [
        "input_tensor, output_tensor = next(iter(dataset))"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7Y7QsykqdLi"
      },
      "source": [
        "x = np.expand_dims(output_tensor[:,1], -1)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DE7fnvAqdLp"
      },
      "source": [
        "def loss_fn(real, pred):\n",
        "    criterion = keras.losses.SparseCategoricalCrossentropy(from_logits=True,\n",
        "                                                           reduction='none')\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    _loss = criterion(real, pred)\n",
        "    mask = tf.cast(mask, dtype=_loss.dtype)\n",
        "    _loss *= mask\n",
        "    return tf.reduce_mean(_loss)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMc7zD6WqdLt"
      },
      "source": [
        "optimizer = tf.optimizers.Adam()"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiAmynEsqdLw"
      },
      "source": [
        "def train_step(input_tensor, target_tensor, enc_hidden):\n",
        "    loss = 0.0\n",
        "    with tf.GradientTape() as tape:\n",
        "    \n",
        "        batch_size = input_tensor.shape[0]\n",
        "        enc_output, enc_hidden = encoder(input_tensor, enc_hidden)\n",
        "\n",
        "        SOS_tensor = np.array([SOS_token])\n",
        "        dec_input = tf.squeeze(tf.expand_dims([SOS_tensor]*batch_size, 1), -1)\n",
        "        dec_hidden = enc_hidden\n",
        "\n",
        "        for tx in range(target_tensor.shape[1]-1):\n",
        "          \n",
        "            dec_out, dec_hidden, _ = decoder(dec_input, dec_hidden,\n",
        "                                            enc_output)\n",
        "            loss += loss_fn(target_tensor[:, tx], dec_out)\n",
        "            dec_input = tf.expand_dims(target_tensor[:, tx], 1)\n",
        "\n",
        "    batch_loss = loss / target_tensor.shape[1]\n",
        "    t_variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "    gradients = tape.gradient(loss, t_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, t_variables))\n",
        "    return batch_loss\n",
        "    "
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kj6diJMqdL0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b13fa82e-3b4a-4211-cf3b-8337961ca97a"
      },
      "source": [
        "hidden = tf.zeros(shape=(16, 256))\n",
        "loss = train_step(input_tensor, output_tensor, hidden)\n",
        "print(loss)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(6.845343, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lk_OG391qdL5"
      },
      "source": [
        "def checkpoint(model, name=None):\n",
        "    if name is not None:\n",
        "        model.save_weights('/content/gdrive/My Drive/{}_fr.h5'.format(name))\n",
        "    else:\n",
        "        raise NotImplementedError"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qUDcmfCmM_C"
      },
      "source": [
        "encoder.load_weights('/content/gdrive/MyDrive/encoder_fr.h5')\n",
        "decoder.load_weights('/content/gdrive/MyDrive/decoder_fr.h5')"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZEbkwx9qdL-"
      },
      "source": [
        "EPOCHS = 10\n",
        "log_every = 50\n",
        "steps_per_epoch = len(pairs) // BATCH_SIZE\n",
        "loss_list = []\n",
        "\n",
        "for e in range(1, EPOCHS):\n",
        "    \n",
        "    total_loss = 0.0\n",
        "    enc_hidden = encoder.init_hidden()\n",
        "    \n",
        "    for idx, (input_tensor, target_tensor) in enumerate(dataset.take(steps_per_epoch)):\n",
        "        batch_loss = train_step(input_tensor, target_tensor, hidden)\n",
        "        total_loss += batch_loss\n",
        "        \n",
        "        if idx % log_every == 0:\n",
        "            loss_list.append(batch_loss)\n",
        "            print(\"Epochs: {} batch_loss: {:.4f}\".format(e, batch_loss))\n",
        "            checkpoint(encoder, 'encoder')\n",
        "            checkpoint(decoder, 'decoder')\n",
        "            \n",
        "    if e % 2 == 0:\n",
        "        print(\"Epochs: {}/{} total_loss: {:.4f}\".format(\n",
        "        e, EPOCHS, total_loss / steps_per_epoch))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlmTbJkmjRib"
      },
      "source": [
        "encoder.save_weights('/content/gdrive/MyDrive/encoder_fr.h5')\n",
        "decoder.save_weights('/content/gdrive/MyDrive/decoder_fr.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuswAWMYqdME"
      },
      "source": [
        "def translate(sentence, max_length=10):\n",
        "    result = ''\n",
        "    attention_plot = np.zeros((10,10))\n",
        "    sentence = normalizeString(sentence)\n",
        "    sentence = sentencetoIndexes(sentence, input_lang)\n",
        "    sentence = keras.preprocessing.sequence.pad_sequences([sentence],padding='post',\n",
        "                                                      maxlen=max_length, truncating='post')\n",
        "    \n",
        "    encoder_hidden = hidden = [tf.zeros((1, 256))]\n",
        "    \n",
        "    enc_out, enc_hidden = encoder(sentence, encoder_hidden)\n",
        "    \n",
        "    dec_hidden = enc_hidden\n",
        "    SOS_tensor = np.array([SOS_token])\n",
        "    dec_input = tf.squeeze(tf.expand_dims([SOS_tensor], 1), -1)\n",
        "    \n",
        "    for tx in range(max_length):\n",
        "        dec_out, dec_hidden, attn_weights = decoder(dec_input,\n",
        "                                                   dec_hidden, enc_out)\n",
        "        attn_weights = tf.reshape(attn_weights, (-1, ))\n",
        "        attention_plot[tx] = attn_weights.numpy()\n",
        "        pred = tf.argmax(dec_out, axis=1).numpy()\n",
        "        result += output_lang.int2word[pred[0]] + \" \"\n",
        "        if output_lang.int2word[pred[0]] == \"EOS\":\n",
        "            break\n",
        "        dec_input = tf.expand_dims(pred, axis=1)\n",
        "    return result, attention_plot"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7mmzYUIqdMI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76a720fe-1e35-4db0-95ff-c41fd87f492d"
      },
      "source": [
        "sentence = \"Je n'aime pas la façon dont tu me parles\"\n",
        "pred, attn_weights = translate(sentence)\n",
        "print(pred)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "i don t love the way you speak with . \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-s9cnSvUxNIC"
      },
      "source": [
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "    #sentence = normalizeString(sentence)\n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    ax.matshow(attention, cmap='viridis')\n",
        "\n",
        "    fontdict = {'fontsize': 14}\n",
        "\n",
        "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpf4T5z_3JP4"
      },
      "source": [
        "from matplotlib import ticker"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5A9xpAf6xsgL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 651
        },
        "outputId": "852d1b13-5888-4d0c-a700-683c824662f0"
      },
      "source": [
        "attn_weights = attn_weights[:len(pred.split(' ')), :len(sentence.split(' '))]\n",
        "plot_attention(attn_weights, sentence.split(), pred.split())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yROfA7newSua"
      },
      "source": [
        "encoder.load_weights('/content/gdrive/My Drive/encoder.h5')\n",
        "decoder.load_weights('/content/gdrive/My Drive/decoder.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vDXB800z9GC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "outputId": "3db16ec6-881b-4c93-ebcc-043fba7574a2"
      },
      "source": [
        "\n",
        "!pip install anvil-uplink\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting anvil-uplink\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/65/776713490bfd5145ddb87834355bf7936bd233b273098e37dc12f1ac253c/anvil_uplink-0.3.36-py2.py3-none-any.whl (61kB)\n",
            "\r\u001b[K     |█████▍                          | 10kB 15.1MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 20kB 17.4MB/s eta 0:00:01\r\u001b[K     |████████████████                | 30kB 20.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 40kB 23.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 51kB 26.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 5.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from anvil-uplink) (0.16.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from anvil-uplink) (1.15.0)\n",
            "Collecting ws4py\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/53/20/4019a739b2eefe9282d3822ef6a225250af964b117356971bd55e274193c/ws4py-0.5.1.tar.gz (51kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 7.1MB/s \n",
            "\u001b[?25hCollecting argparse\n",
            "  Downloading https://files.pythonhosted.org/packages/f2/94/3af39d34be01a24a6e65433d19e107099374224905f1e0cc6bbe1fd22a2f/argparse-1.4.0-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: ws4py\n",
            "  Building wheel for ws4py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ws4py: filename=ws4py-0.5.1-cp37-none-any.whl size=45230 sha256=bb8721cd253ce325fbee4f4612210619d8a4d1d8a8c6362693cbaae606b56be8\n",
            "  Stored in directory: /root/.cache/pip/wheels/a2/6e/4e/8b0ae12fb9b8a05715256952cf7609a8ab86285fab99b88c68\n",
            "Successfully built ws4py\n",
            "Installing collected packages: ws4py, argparse, anvil-uplink\n",
            "Successfully installed anvil-uplink-0.3.36 argparse-1.4.0 ws4py-0.5.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "argparse",
                  "google"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9kwSgOtPRDJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTRNZSNdQR1F",
        "outputId": "6a2101f9-42ea-471c-e125-3c58b38bd023"
      },
      "source": [
        "import anvil.server\n",
        "\n",
        "anvil.server.connect(\"MGQSYXEMZEBIIKRHJ3PATCQG-4WA5U74KV5JQOJHG\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Disconnecting from previous connection first...\n",
            "Connecting to wss://anvil.works/uplink\n",
            "Anvil websocket open\n",
            "Connected to \"Default environment (dev)\" as SERVER\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSz-mOooPot_"
      },
      "source": [
        "@anvil.server.callable\n",
        "def translate(sentence, max_length=10):\n",
        "    result = ''\n",
        "    attention_plot = np.zeros((10,10))\n",
        "    sentence = normalizeString(sentence)\n",
        "    sentence = sentencetoIndexes(sentence, input_lang)\n",
        "    sentence = keras.preprocessing.sequence.pad_sequences([sentence],padding='post',\n",
        "                                                      maxlen=max_length, truncating='post')\n",
        "    \n",
        "    encoder_hidden = hidden = [tf.zeros((1, 256))]\n",
        "    \n",
        "    enc_out, enc_hidden = encoder(sentence, encoder_hidden)\n",
        "    \n",
        "    dec_hidden = enc_hidden\n",
        "    SOS_tensor = np.array([SOS_token])\n",
        "    dec_input = tf.squeeze(tf.expand_dims([SOS_tensor], 1), -1)\n",
        "    \n",
        "    for tx in range(max_length):\n",
        "        dec_out, dec_hidden, attn_weights = decoder(dec_input,\n",
        "                                                   dec_hidden, enc_out)\n",
        "        attn_weights = tf.reshape(attn_weights, (-1, ))\n",
        "        attention_plot[tx] = attn_weights.numpy()\n",
        "        pred = tf.argmax(dec_out, axis=1).numpy()\n",
        "        result += output_lang.int2word[pred[0]] + \" \"\n",
        "        if output_lang.int2word[pred[0]] == \"EOS\":\n",
        "            break\n",
        "        dec_input = tf.expand_dims(pred, axis=1)\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIAf3mWMP1wD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}